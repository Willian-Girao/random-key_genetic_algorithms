# Random-Key Genetic Algorithms

## Introduction
Random-Key Genetic Algorithm (RKGA) is a new class of John Holland's Genetic Algorithms (GA). This new class described by Bean[6] works somewhat similarly to GA's, applying the Darwinian principle of survival of the fittest, with a few differences related to the encoding/decoding and manipulation of the generations, representing the possible solutions of an optimization problem as permutation vectors composed of random keys.

[6] J. C. Bean. Genetic algorithms and random keys for sequencing and optimization. ORSA J. on Computing, 6:154–160, 1994.

## Overview
A RKGA is an evolutionary metaheuristic for discrete and global optimization. Each solution is encoded as an array og *n* random keys where a random key is a real number, randomly generated, in the continuous interval [0,1).

A decoder maps each array of random keys to a solution of the optimization problem being solved and computes its cost.

The algorithm starts with a population of *p* arrays of random keys. At each iteration, the arrays are partitioned into two sets: a smaller set of high-valued elite solutions and the remaining non-elite solutions forming another set.

All elite elements are copied, without change, to the next population. A small number of random-key arrays (the mutants) are added to the population of the next iteration. The remaining elements of the population of the next iteration are generated by combining, with parametrized uniform crossover of Spears and DeJong (On the virtues of parameterized uniform crossover. In: Proceedings of the fourth international conference on genetic algorithms, San Mateo, pp 230–236, 1991), paris of arrays.

[1] http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.567.6832&rep=rep1&type=pdf

## Algorithmic behavior
The algorithm starts by generating a population of *p* vectors of *n* random keys, which is referred to as the *1st* generation.

In the *k-th* generation, the *p* vectors of the population are partitioned into two sets: a small set of *p_e < p/2* vectors corresponding to the best solutions (called *elite* set) and a bigger set with the remainder of the population (called *non-elite* set).

All elite vectors of the current *k-th* generation are copied, **unchanged**, to the population of the *k+1-th* (next) generation. Next, *p_m* vectors of random keys are introduced into the population of the *k+1-th* generation. These vectors, called *mutants*, <code>play the same role as the mutation operators of classical genetic algorithms</code>.

To complete the *p* elements of the population of the *k+1-th* generation, *p - p_e - p_m* vectors are generated, combining pairs of solutions from the population of the *k-th* (current) generation, with a <code>parametrized uniform crossover</code>. This process is described bellow:

Let *a* and *b* be the selected vectors for mating and let *c* be the offspring produced. In the crossover of Spears and DeJong [58], *c[i]*, the *i-th* component of the offspring vector, receives the *i-th* key of one of its parents. It receives the key *a[i]* with probability *p_a* and *b[i]* with probability *p_b = 1 - p\_a*.

![alt text](https://github.com/Willian-Girao/random-key_genetic_algorithms/blob/master/algorithm_cycle.jpg)

## Decoder
A *decoder* is a deterministic algorithm that takes as input a random-key vector and returns a feasible solution of the optimization problem and its cost. The decoder proposed by Bean (2014) simply orders the elements of the vector of random keys, thus producing a permutation corresponding to the indices of the sorted elements.

Thus, a random-key GA searches the solution space indirectly by searching the space of random keys and using the decoder to evaluate the fitness of the vector.

## Common Parameters Settings

- Size of population: a function of *N*, say *N* or *2N*
- Size of elite partition: 15-25% of population
- Size of mutant set: 5-15% of population
- Child inheritance (from elite) probability: > 0.5, say 0.7

# Data Mule Scheduling Problem

https://pdfs.semanticscholar.org/f339/7ec243dce5fd5869cf523a3ee1a77c54957a.pdf
https://link.springer.com/referenceworkentry/10.1007%2F978-3-319-07153-4_30-1

## Introduction

A usual way to collect data in a Wireless Sensor Network (WSN) is by the support of a special agent, called data mule, that moves among sensors nodes and performs all communication between them. A data mule is a mobile node that moves inside the field (network) and collects data from sensors within the network. The Data Mule Scheduling Problem (DMSP) consists in planning the route of the data mule, the order of attendence of the sensors, and also plan the velocity it will use to move. The idea os that each sensor in the network generates some amount of information per unit of time and it has a limited amount of memory to retain this information generated, and when the amount of information generated exceeds the memory capacity, information is lost. The data mule work is to prevent information loss by visiting and retreaving the sensors information to free its memory, preventing the information losss.

We cam decompose  the problem into the following three subproblems:
- Path selection: which trajectory the data mule follows
- Speed control: how the data mule changes the speed during the travel
- Job scheduling: from which sensor the data mule collects data at each time point

**Path selction** is to determine the trajectory of the data mule in the network. To collect data from each particular sensor, the data mule needs to go within the sensor's communication range at least once. Depending on the mobility capacity of the mule, there can be some constraints on the path, such as minimum turning radious.

Once the path is chosen, 2-D/3-D data mule scheduling problems are reduced to 1-D data mule scheduling problem, in which the communication ranges of each node are given as intervals on the location axis. **Spped control** is to determine how the data mule changes its speed along the chosen path. The data mule needs to change the speed so that it stays within each node's communication range long enough to collect all the data from it. The objective in this problem is to find an optimal time-speed profile while satisfying that constraint.

Once we have a time-speed profile, we have a mapping from each location to time point. Thus we get a scheduling problem by regarding data collection from each sensor as a job. Each job has one or more intervals in which it can be executed. **Job scheduling** is to determine the allocation of time slots to jobs so that all jobs can be completed.

![alt text](https://github.com/Willian-Girao/random-key_genetic_algorithms/blob/master/substeps_dmsp.png)
